version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - OLLAMA_HOST=https://ollama.com
      - OLLAMA_MODEL=gpt-oss:120b
      - OLLAMA_API_KEY=eec778b3ee2845bcad7c602cc2db45c3.Tn7qWVi3POVyg6u9rRzLbofz
      - GROQ_API_KEY=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
      - GROQ_MODEL=llama-3.3-70b-versatile
      - REDIS_URL=redis://redis:6379
      - LOG_LEVEL=INFO
      - EMBEDDING_PROVIDER=huggingface
      - EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
    depends_on:
      - redis
    networks:
      - amparo-network
    restart: unless-stopped

  redis:
    image: redis:7
    ports:
      - "6379:6379"
    networks:
      - amparo-network
    restart: unless-stopped
    volumes:
      - redis-data:/data

networks:
  amparo-network:
    driver: bridge

volumes:
  redis-data:
